{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "Y-gOizLgyrz9"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "def initialize_network_parameters(layer_dims):\n",
        "    np.random.seed(42)\n",
        "    parameters = {}\n",
        "    number_layers = len(layer_dims)\n",
        "\n",
        "    for i in range(1, number_layers):\n",
        "        parameters[f'W{i}'] = np.random.randn(layer_dims[i-1], layer_dims[i]) * 0.01\n",
        "        parameters[f'b{i}'] = np.zeros((1, layer_dims[i]))\n",
        "\n",
        "    return parameters\n",
        "\n",
        "def activation_relu(Z):\n",
        "    return np.maximum(0, Z)\n",
        "\n",
        "def activation_relu_derivative(dA, Z):\n",
        "    dZ = np.where(Z > 0, dA, 0)\n",
        "    return dZ\n",
        "\n",
        "def activation_sigmoid(Z):\n",
        "    return 1 / (1 + np.exp(-Z))\n",
        "\n",
        "def activation_sigmoid_derivative(dA, Z):\n",
        "    s = activation_sigmoid(Z)\n",
        "    return dA * s * (1 - s)\n",
        "\n",
        "def forward_propagation(X, parameters):\n",
        "    caches = []\n",
        "    A = X\n",
        "    num_layers = len(parameters) // 2\n",
        "\n",
        "    for i in range(1, num_layers):\n",
        "        A_prev = A\n",
        "        W = parameters[f'W{i}']\n",
        "        b = parameters[f'b{i}']\n",
        "        Z = np.dot(A_prev, W) + b\n",
        "        A = activation_relu(Z)\n",
        "        caches.append((A_prev, W, b, Z))\n",
        "\n",
        "    Z_final = np.dot(A, parameters[f'W{num_layers}']) + parameters[f'b{num_layers}']\n",
        "    A_final = activation_sigmoid(Z_final)\n",
        "    caches.append((A, parameters[f'W{num_layers}'], parameters[f'b{num_layers}'], Z_final))\n",
        "\n",
        "    return A_final, caches\n",
        "\n",
        "def predict(X, parameters):\n",
        "\n",
        "    A_final, _ = forward_propagation(X, parameters)\n",
        "    predictions = A_final > 0.5  # Using 0.5 as the threshold for binary classification\n",
        "    return predictions\n",
        "\n",
        "def compute_cost(A_final, Y):\n",
        "    m = Y.shape[0]\n",
        "    cost = -np.sum(Y * np.log(A_final) + (1 - Y) * np.log(1 - A_final)) / m\n",
        "    return np.squeeze(cost)\n",
        "\n",
        "def backward_propagation(A_final, Y, caches):\n",
        "    grads = {}\n",
        "    num_layers = len(caches)\n",
        "    m = A_final.shape[0]\n",
        "    Y = Y.reshape(A_final.shape)\n",
        "    dA_final = -(np.divide(Y, A_final) - np.divide(1 - Y, 1 - A_final))\n",
        "\n",
        "    current_cache = caches[-1]\n",
        "    grads[f'dA{num_layers}'], grads[f'dW{num_layers}'], grads[f'db{num_layers}'] = linear_activation_backward(dA_final, current_cache, 'sigmoid')\n",
        "\n",
        "    for i in reversed(range(num_layers - 1)):\n",
        "        current_cache = caches[i]\n",
        "        dA_prev, dW, db = linear_activation_backward(grads[f'dA{i+2}'], current_cache, 'relu')\n",
        "        grads[f'dA{i+1}'], grads[f'dW{i+1}'], grads[f'db{i+1}'] = dA_prev, dW, db\n",
        "\n",
        "    return grads\n",
        "\n",
        "def update_network_parameters(parameters, grads, learning_rate):\n",
        "    num_layers = len(parameters) // 2\n",
        "\n",
        "    for i in range(1, num_layers + 1):\n",
        "        parameters[f'W{i}'] -= learning_rate * grads[f'dW{i}']\n",
        "        parameters[f'b{i}'] -= learning_rate * grads[f'db{i}']\n",
        "\n",
        "    return parameters\n",
        "\n",
        "def linear_backward(dZ, cache):\n",
        "    A_prev, W, _, _ = cache\n",
        "    m = A_prev.shape[0]\n",
        "    dW = np.dot(A_prev.T, dZ) / m\n",
        "    db = np.sum(dZ, axis=0, keepdims=True) / m\n",
        "    dA_prev = np.dot(dZ, W.T)\n",
        "\n",
        "    return dA_prev, dW, db\n",
        "\n",
        "def linear_activation_backward(dA, cache, activation):\n",
        "    _, W, _, Z = cache\n",
        "    if activation == 'relu':\n",
        "        dZ = activation_relu_derivative(dA, Z)\n",
        "    elif activation == 'sigmoid':\n",
        "        dZ = activation_sigmoid_derivative(dA, Z)\n",
        "    return linear_backward(dZ, cache)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def train(X_train, y_train, layer_dims, learning_rate=0.0075, num_iterations=3000, print_cost=True):\n",
        "    np.random.seed(1)\n",
        "    costs = []\n",
        "\n",
        "    # Updated function name to initialize_network_parameters\n",
        "    parameters = initialize_network_parameters(layer_dims)\n",
        "\n",
        "    for i in range(num_iterations):\n",
        "        # Updated function name to forward_propagation\n",
        "        A_final, caches = forward_propagation(X_train, parameters)\n",
        "\n",
        "        # Updated variable name A_final instead of AL\n",
        "        cost = compute_cost(A_final, y_train)\n",
        "\n",
        "        # Updated function name to backward_propagation and A_final instead of AL\n",
        "        grads = backward_propagation(A_final, y_train, caches)\n",
        "\n",
        "        # Updated function name to update_network_parameters\n",
        "        parameters = update_network_parameters(parameters, grads, learning_rate)\n",
        "\n",
        "        if print_cost and i % 100 == 0:\n",
        "            print(f\"Cost after iteration {i}: {cost:.6f}\")\n",
        "            costs.append(cost)\n",
        "\n",
        "    return parameters, costs\n"
      ],
      "metadata": {
        "id": "6xsFwCDbNwr9"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_wine\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "\n",
        "def load_and_prepare_data():\n",
        "    # Load the dataset\n",
        "    wine_data = load_wine()\n",
        "    features = wine_data.data[:, :10]  # Using only the first 10 features\n",
        "    targets = (wine_data.target == 1).astype(int)  # Adjust for binary classification\n",
        "\n",
        "    # Split the dataset into training and testing sets\n",
        "    X_train, X_test, y_train, y_test = train_test_split(features, targets, test_size=0.2, random_state=42)\n",
        "\n",
        "    # Normalize X_train and X_test\n",
        "    mean = np.mean(X_train, axis=0)\n",
        "    std = np.std(X_train, axis=0)\n",
        "    X_train_normalized = (X_train - mean) / std\n",
        "    X_test_normalized = (X_test - mean) / std\n",
        "\n",
        "    # Normalize the features\n",
        "    scaler = StandardScaler()\n",
        "    X_train = scaler.fit_transform(X_train)\n",
        "    X_test = scaler.transform(X_test)\n",
        "\n",
        "    # Ensure y_train and y_test are the correct shape\n",
        "    y_train = y_train.reshape(-1, 1)\n",
        "    y_test = y_test.reshape(-1, 1)\n",
        "\n",
        "    return X_train_normalized, X_test_normalized, y_train, y_test\n",
        "\n",
        "def train(X_train, y_train, layer_dimensions, learning_rate=0.01, num_iterations=1500, print_cost=True):\n",
        "    # Assuming a training function that initializes parameters, conducts forward and backward propagation, and updates weights\n",
        "    parameters = initialize_network_parameters(layer_dimensions)\n",
        "    costs = []\n",
        "\n",
        "    for i in range(num_iterations):\n",
        "        AL, caches = forward_propagation(X_train, parameters)\n",
        "        cost = compute_cost(AL, y_train)\n",
        "        grads = backward_propagation(AL, y_train, caches)\n",
        "        parameters = update_parameters(parameters, grads, learning_rate)\n",
        "\n",
        "        if print_cost and i % 100 == 0:\n",
        "            print(f\"Cost after iteration {i}: {cost:.6f}\")\n",
        "            costs.append(cost)\n",
        "\n",
        "    return parameters, costs\n",
        "\n",
        "# Main execution\n",
        "X_train, X_test, y_train, y_test = load_and_prepare_data()\n",
        "layer_dimensions = [10, 10, 8, 8, 4, 1]  # 5 layers\n",
        "parameters, costs = train(X_train, y_train, layer_dimensions, learning_rate=0.01, num_iterations=1500, print_cost=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9WEdKOoFzEAv",
        "outputId": "2d6d40ec-cf03-4663-f10f-90410fb9b73b"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cost after iteration 0: 0.693147\n",
            "Cost after iteration 100: 0.685490\n",
            "Cost after iteration 200: 0.680844\n",
            "Cost after iteration 300: 0.678019\n",
            "Cost after iteration 400: 0.676298\n",
            "Cost after iteration 500: 0.675247\n",
            "Cost after iteration 600: 0.674604\n",
            "Cost after iteration 700: 0.674209\n",
            "Cost after iteration 800: 0.673967\n",
            "Cost after iteration 900: 0.673818\n",
            "Cost after iteration 1000: 0.673726\n",
            "Cost after iteration 1100: 0.673670\n",
            "Cost after iteration 1200: 0.673635\n",
            "Cost after iteration 1300: 0.673613\n",
            "Cost after iteration 1400: 0.673600\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "\n",
        "def accuracy(predictions, labels):\n",
        "    \"\"\" Calculates the accuracy of predictions against the true labels. \"\"\"\n",
        "    return np.mean(predictions == labels) * 100\n",
        "\n",
        "def predict_and_evaluate(X_test, parameters, y_test):\n",
        "    # Predict test set outcomes\n",
        "    test_predictions = predict(X_test, parameters)\n",
        "\n",
        "    # Calculate the accuracy on the test set\n",
        "    test_accuracy = accuracy(test_predictions, y_test)  # Ensure the accuracy function is correctly defined\n",
        "    print(f\"Test Accuracy: {test_accuracy:.2f}%\")\n",
        "\n",
        "    # Generate a confusion matrix\n",
        "    test_confusion_matrix = confusion_matrix(y_test, test_predictions)\n",
        "    print(\"Confusion Matrix:\\n\", test_confusion_matrix)\n",
        "\n",
        "    # Detailed classification report (Precision, Recall, F1-Score)\n",
        "    detailed_report = classification_report(y_test, test_predictions)\n",
        "    print(\"Classification Report:\\n\", detailed_report)\n",
        "\n",
        "    return test_accuracy\n",
        "\n",
        "# Define your neural network architecture here, for example:\n",
        "layer_dimensions = [10, 5, 1]  # Example layer dimensions\n",
        "\n",
        "# Hyperparameter tuning setup\n",
        "learning_rates = [0.1, 0.01, 0.001]\n",
        "epochs = [500, 1500, 3000]\n",
        "best_accuracy = 0\n",
        "best_lr = 0\n",
        "best_epoch = 0\n",
        "\n",
        "for lr in learning_rates:\n",
        "    for epoch in epochs:\n",
        "        print(f\"Training model with learning rate: {lr} and epochs: {epoch}\")\n",
        "        parameters, costs = train(X_train, y_train, layer_dimensions, learning_rate=lr, num_iterations=epoch, print_cost=False)\n",
        "        current_accuracy = predict_and_evaluate(X_test, parameters, y_test)\n",
        "\n",
        "        if current_accuracy > best_accuracy:\n",
        "            best_accuracy = current_accuracy\n",
        "            best_lr = lr\n",
        "            best_epoch = epoch\n",
        "\n",
        "print(f\"Best Test Accuracy: {best_accuracy:.2f}% with Learning Rate: {best_lr} and Epochs: {best_epoch}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xqmAFgsANceV",
        "outputId": "074fea47-2f84-4e52-d582-7ceaf4fe8fdf"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training model with learning rate: 0.1 and epochs: 500\n",
            "Test Accuracy: 97.22%\n",
            "Confusion Matrix:\n",
            " [[22  0]\n",
            " [ 1 13]]\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      1.00      0.98        22\n",
            "           1       1.00      0.93      0.96        14\n",
            "\n",
            "    accuracy                           0.97        36\n",
            "   macro avg       0.98      0.96      0.97        36\n",
            "weighted avg       0.97      0.97      0.97        36\n",
            "\n",
            "Training model with learning rate: 0.1 and epochs: 1500\n",
            "Test Accuracy: 97.22%\n",
            "Confusion Matrix:\n",
            " [[22  0]\n",
            " [ 1 13]]\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      1.00      0.98        22\n",
            "           1       1.00      0.93      0.96        14\n",
            "\n",
            "    accuracy                           0.97        36\n",
            "   macro avg       0.98      0.96      0.97        36\n",
            "weighted avg       0.97      0.97      0.97        36\n",
            "\n",
            "Training model with learning rate: 0.1 and epochs: 3000\n",
            "Test Accuracy: 97.22%\n",
            "Confusion Matrix:\n",
            " [[22  0]\n",
            " [ 1 13]]\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      1.00      0.98        22\n",
            "           1       1.00      0.93      0.96        14\n",
            "\n",
            "    accuracy                           0.97        36\n",
            "   macro avg       0.98      0.96      0.97        36\n",
            "weighted avg       0.97      0.97      0.97        36\n",
            "\n",
            "Training model with learning rate: 0.01 and epochs: 500\n",
            "Test Accuracy: 61.11%\n",
            "Confusion Matrix:\n",
            " [[22  0]\n",
            " [14  0]]\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.61      1.00      0.76        22\n",
            "           1       0.00      0.00      0.00        14\n",
            "\n",
            "    accuracy                           0.61        36\n",
            "   macro avg       0.31      0.50      0.38        36\n",
            "weighted avg       0.37      0.61      0.46        36\n",
            "\n",
            "Training model with learning rate: 0.01 and epochs: 1500\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 100.00%\n",
            "Confusion Matrix:\n",
            " [[22  0]\n",
            " [ 0 14]]\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        22\n",
            "           1       1.00      1.00      1.00        14\n",
            "\n",
            "    accuracy                           1.00        36\n",
            "   macro avg       1.00      1.00      1.00        36\n",
            "weighted avg       1.00      1.00      1.00        36\n",
            "\n",
            "Training model with learning rate: 0.01 and epochs: 3000\n",
            "Test Accuracy: 100.00%\n",
            "Confusion Matrix:\n",
            " [[22  0]\n",
            " [ 0 14]]\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        22\n",
            "           1       1.00      1.00      1.00        14\n",
            "\n",
            "    accuracy                           1.00        36\n",
            "   macro avg       1.00      1.00      1.00        36\n",
            "weighted avg       1.00      1.00      1.00        36\n",
            "\n",
            "Training model with learning rate: 0.001 and epochs: 500\n",
            "Test Accuracy: 61.11%\n",
            "Confusion Matrix:\n",
            " [[22  0]\n",
            " [14  0]]\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.61      1.00      0.76        22\n",
            "           1       0.00      0.00      0.00        14\n",
            "\n",
            "    accuracy                           0.61        36\n",
            "   macro avg       0.31      0.50      0.38        36\n",
            "weighted avg       0.37      0.61      0.46        36\n",
            "\n",
            "Training model with learning rate: 0.001 and epochs: 1500\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 61.11%\n",
            "Confusion Matrix:\n",
            " [[22  0]\n",
            " [14  0]]\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.61      1.00      0.76        22\n",
            "           1       0.00      0.00      0.00        14\n",
            "\n",
            "    accuracy                           0.61        36\n",
            "   macro avg       0.31      0.50      0.38        36\n",
            "weighted avg       0.37      0.61      0.46        36\n",
            "\n",
            "Training model with learning rate: 0.001 and epochs: 3000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 61.11%\n",
            "Confusion Matrix:\n",
            " [[22  0]\n",
            " [14  0]]\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.61      1.00      0.76        22\n",
            "           1       0.00      0.00      0.00        14\n",
            "\n",
            "    accuracy                           0.61        36\n",
            "   macro avg       0.31      0.50      0.38        36\n",
            "weighted avg       0.37      0.61      0.46        36\n",
            "\n",
            "Best Test Accuracy: 100.00% with Learning Rate: 0.01 and Epochs: 1500\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    }
  ]
}